#############################################################################
 #
 #  This file is part of Verkko, a software program that assembles
 #  whole-genome sequencing reads into telomere-to-telomere
 #  haplotype-resolved chromosomes.
 #
 #  Except as indicated otherwise, this is a 'United States Government
 #  Work', and is released in the public domain.
 #
 #  File 'README.licenses' in the root directory of this distribution
 #  contains full conditions and disclaimers.
 #
 ##

#
#  Rule extractONT extracts the ONT reads used for gap filling from
#  the input sequences.  These are passed to consensus.
#
#  See comments in 3-combineONT for details on the functions.
#
#  Configuration Parameters:
#    ...
#


def extractONTI(wildcards):
    return expand("3-align/split/ont{nnnn}.fasta.gz", nnnn = glob_wildcards("3-align/split/ont{xxxx}.fasta.gz").xxxx)

def extractONTP(wildcards):
    return expand("ont{nnnn}.fasta.gz", nnnn = glob_wildcards("3-align/split/ont{xxxx}.fasta.gz").xxxx)

rule extractONT:
    input:
        split_finished = {rules.splitONT.output.finished},
        ont_files      = extractONTI,
        ont_gap_align  = {rules.refillGapONTs.output.ont_gap_align}
    output:
        ont_subset_id  = '7-consensus/ont_subset.id',
        ont_subset_ex  = '7-consensus/ont_subset.extract',
        ont_subset     = '7-consensus/ont_subset.fasta.gz'
    log:
        err            = '7-consensus/extractONT.err'
    params:
        ont_files      = extractONTP,
        keepinter      = config['keep_intermediate']
    threads:
        int(config['sub_n_cpus'])
    resources:
        job_id = 1,
        n_cpus = config['sub_n_cpus'],
        mem_gb = lambda wildcards, input, attempt: getMemoryRequest(attempt, 'sub'),
        time_h = config['sub_time_h']
    shell:
        '''
cd 7-consensus

cat > ./extractONT.sh << EOF
#!/bin/sh
set -e

#  Extract IDs of the reads used for gap filling.  Sorting and unique-ifying
#  isn't required for the algorithm but might be helpful for searching the
#  file.
#
cut -f 1 ../{input.ont_gap_align} \\\\
| \\\\
sort -u > ../{output.ont_subset_id}

#  Build command lines for extracting those reads from
#  all the partitioned input files.
#
rm -f ../7-consensus/{output.ont_subset_ex}

for fn in {params.ont_files} ; do
  echo >> ../{output.ont_subset_ex} extract \\$fn ../{output.ont_subset_id} ../3-align/split/\\$fn
done

#  Extract reads in parallel for each input.
#
xargs -L 1 -P {threads} \\\\
  {PYTHON} {VERKKO}/scripts/process_reads.py \\\\
< ../{output.ont_subset_ex}

#  Combine all the pieces.
#
cat {params.ont_files} > ../{output.ont_subset}

#  Cleanup.
#
rm -f {params.ont_files}

if [ {params.keepinter} = "False" ] ; then
  rm -rf ../3-align/split
fi
EOF

chmod +x ./extractONT.sh

./extractONT.sh > ../{log.err} 2>&1
        '''
