#############################################################################
 #
 #  This file is part of Verkko, a software program that assembles
 #  whole-genome sequencing reads into telomere-to-telomere
 #  haplotype-resolved chromosomes.
 #
 #  Except as indicated otherwise, this is a 'United States Government
 #  Work', and is released in the public domain.
 #
 #  File 'README.licenses' in the root directory of this distribution
 #  contains full conditions and disclaimers.
 #
 ##

#
#  Rule extractONT extracts the ONT reads used for gap filling from
#  the input sequences.  These are passed to consensus.
#

rule extractONT:
    input:
        ont_gap_align  = rules.processONT.output.ont_gap_align,
        split_finished = rules.splitONT.output.split_finished
    output:
        ont_subset_id  = '7-consensus/ont_subset.id',
        ont_subset_ex  = '7-consensus/ont_subset.extract',
        ont_subset     = '7-consensus/ont_subset.fasta.gz'
    log:
        err            = '7-consensus/extractONT.err'
    params:
        ext_files      = lambda wildcards: expand("ont{nnnn}.fasta.gz", nnnn = splitONToutputs(wildcards)),
    threads:
        int(config['sub_n_cpus'])
    resources:
        job_id = 1,
        n_cpus = int(config['sub_n_cpus']),
        mem_gb = lambda wildcards, input, attempt: getMemoryRequest(attempt, 'sub'),
        time_h = int(config['sub_time_h'])
    shell:
        '''
cd 7-consensus

cat > ./extractONT.sh << EOF
#!/bin/sh
set -e

#  1) Extract IDs of the reads used for gap filling.  Sorting and
#  unique-ifying isn't required for the algorithm but might be helpful for
#  searching the file.
#
#  2) Build a list of command lines for extracting those reads from all the
#  partitioned input files.  The location of these input files is hardcoded;
#  snakemake is not used to generate it.  Snakemake knows only that
#  split_finished exists.
#
#  3) Use xargs to extract reads in parallel.  xargs will call
#  'process_reads.py <inputline>' for each line in its input.
#
#  4) Combine all the pieces, then remove the extracted pieces and full split
#  files, leaving the .finished file so snakemake doesn't (erroneously) try
#  to regenerate them.

cut -f 1 ../{input.ont_gap_align} \\\\
| \\\\
sort -u > ../{output.ont_subset_id}

rm -f ../{output.ont_subset_ex}

for fn in {params.ext_files} ; do
  echo >> ../{output.ont_subset_ex} extract \\$fn ../{output.ont_subset_id} ../3-align/split/\\$fn
done

xargs -L 1 -P {threads} < ../{output.ont_subset_ex} \\\\
  {PYTHON} {VERKKO}/scripts/process_reads.py

cat {params.ext_files} > ../{output.ont_subset}
rm -f {params.ext_files}
EOF

chmod +x ./extractONT.sh

./extractONT.sh > ../{log.err} 2>&1
        '''
