#############################################################################
 #
 #  This file is part of Verkko, a software program that assembles
 #  whole-genome sequencing reads into telomere-to-telomere
 #  haplotype-resolved chromosomes.
 #
 #  Except as indicated otherwise, this is a 'United States Government
 #  Work', and is released in the public domain.
 #
 #  File 'README.licenses' in the root directory of this distribution
 #  contains full conditions and disclaimers.
 #
 ##


HIFI_READS = config.get('HIFI_READS')
ONT_READS  = config.get('ONT_READS')
HIC_READS1  = config.get('HIC_READS1')
HIC_READS2  = config.get('HIC_READS2')
HAPLO_DIV = float(config.get('haplo_divergence'))
VERKKO = config.get('VERKKO')


rule copyFiles:
    input:
        unitig_scfmap = '6-layoutContigs/unitig-popped.layout.scfmap',
        unitig_assembly = '7-consensus/combined.fasta',
        unitig_graph = rules.verkko.input.graph,
        hifi5cov    = rules.verkko.input.hifi5cov
    log:
        err    = '8-hicPipeline/prepare_hic.err'
    threads:
        int(config['fhc_n_cpus'])
    resources:
        job_id = 1,
        n_cpus = int(config['fhc_n_cpus']),
        mem_gb = lambda wildcards, input, attempt: getMemoryRequest(attempt, 'fhc'),
        time_h = lambda wildcards, input, attempt: getTimeRequest(attempt, 'fhc')
    output:
        rename_map = '8-hicPipeline/contigs_rename.map',
        unitig_fasta = '8-hicPipeline/unitigs.fasta',
        unitig_hpc = '8-hicPipeline/unitigs.hpc.fasta' ,
        unitig_graph = '8-hicPipeline/unitigs.hpc.noseq.gfa',
        finalnseqgraph = 'assembly.homopolymer-compressed.noseq.gfa'
    shell:
        '''
cd 8-hicPipeline
cat > ./prepare_hic.sh <<EOF
#!/bin/sh
set -e
cat ../{input.unitig_scfmap} | awk '{{if (match(\$1, "path")) print \$2"\\t"\$3}}' > ../{output.rename_map}
{PYTHON} {VERKKO}/scripts/fasta_combine.py rename ../{output.unitig_fasta}  ../{output.rename_map} ../{input.unitig_assembly}

awk '/^S/{{print ">"\$2"\\n"\$3}}' ../{input.unitig_graph} > ../{output.unitig_hpc}
awk < ../{input.unitig_graph} \\\\
  'BEGIN \\\\
   {{ \\\\
     FS="[ \\t]+"; OFS="\\t"; \\\\
   }} \\\\
   {{ \\\\
     if (\$1 == "S") {{ \\\\
       print "S", \$2, "*", "LN:i:"length(\$3); \\\\
     }} else {{ \\\\
       print \$0; \\\\
     }} \\\\
   }}' \\\\
| \\\\
{PYTHON} {VERKKO}/scripts/inject_coverage.py --allow-absent \\\\
  ../{input.hifi5cov} \\\\
> ../{output.unitig_graph}
cp ../{output.unitig_graph} ../{output.finalnseqgraph}
EOF

chmod +x ./prepare_hic.sh

./prepare_hic.sh > ../{log.err} 2>&1
        '''

rule runMashMap:
    input:
        unitigs_hpc = '8-hicPipeline/unitigs.hpc.fasta',
        unitigs = '8-hicPipeline/unitigs.fasta'
    output:
        unitigs_hpc50 = '8-hicPipeline/unitigs_hpc50.mashmap',
        unitigs_nohpc50 = '8-hicPipeline/unitigs_nonhpc50.mashmap'
    log:
        err    = '8-hicPipeline/run_mashmap.err'
    params:
        MASHMAP   = config.get('MASHMAP', "{VERKKO}/bin/mashmap"),
        MASHMAP_DIV = 100 - 100*float(config['haplo_divergence'])
    threads:
        int(config['fhc_n_cpus'])

    resources:
        job_id = 1,
        n_cpus = int(config['fhc_n_cpus']),
        mem_gb = lambda wildcards, input, attempt: getMemoryRequest(attempt, 'fhc'),
        time_h = lambda wildcards, input, attempt: getTimeRequest(attempt, 'fhc')
    shell:
        '''
cd 8-hicPipeline

cat > ./run_mashmap.sh <<EOF
#!/usr/bin/env bash
set -e -o pipefail

echo "---Running MashMap"
{params.MASHMAP} -r ../{input.unitigs_hpc} -q ../{input.unitigs_hpc} -t {threads} -f none --pi {params.MASHMAP_DIV} -s 10000 -o >(awk '\$11 >= 50000' > ../{output.unitigs_hpc50})
{params.MASHMAP} -r ../{input.unitigs} -q ../{input.unitigs} -t {threads} -f none --pi {params.MASHMAP_DIV} -s 10000 -o >(awk '\$11 >= 50000' > ../{output.unitigs_nohpc50})
EOF

chmod +x ./run_mashmap.sh

./run_mashmap.sh > ../{log.err} 2>&1
        '''

#TODO constants to yml
rule prepareScaffolding:
    input:
        unitigs_hpc = '8-hicPipeline/unitigs.hpc.fasta',
        graph_hpc = '8-hicPipeline/unitigs.hpc.noseq.gfa',
        uncompressed_unitigs = '8-hicPipeline/unitigs.fasta',
        rukki_tsv = '8-hicPipeline/prescaf_rukki.paths.tsv'
    output:
        path_mashmap = '8-hicPipeline/paths2ref.mashmap',
        paths_hpc = '8-hicPipeline/paths.hpc.fasta',        
        ids_list = '8-hicPipeline/scaffolding_nodes.list'
    log:
        err    = '8-hicPipeline/prepare_ref_mashmap.err'
    params:
        MASHMAP   = config.get('MASHMAP', "{VERKKO}/bin/mashmap"),
        MASHMAP_DIV = 100 - 100*float(config['haplo_divergence']),
        ref = config['ref'] if config['with_ref'] == "True" else '../8-hicPipeline/paths.hpc.fasta'
    threads:
        int(config['fhc_n_cpus'])
    resources:
        job_id = 1,
        n_cpus = int(config['fhc_n_cpus']),
        mem_gb = lambda wildcards, input, attempt: getMemoryRequest(attempt, 'fhc'),
        time_h = lambda wildcards, input, attempt: getTimeRequest(attempt, 'fhc')
    shell:
        '''
cd 8-hicPipeline

cat > ./prepare_ref_mashmap.sh <<EOF
#!/usr/bin/env bash
set -e
echo "---Preparing rukki paths fasta"
{PYTHON} {VERKKO}/scripts/prepare_scaffolding.py ../{input.rukki_tsv} ../{input.unitigs_hpc} ../{input.graph_hpc} ../{output.paths_hpc} ../{output.ids_list} 20000 5000000 ../{input.uncompressed_unitigs}

echo "---Running MashMap"
{params.MASHMAP} -r {params.ref}  -q ../8-hicPipeline/paths.hpc.fasta -t {threads}  -f none --pi {params.MASHMAP_DIV} -s 10000 -o >(awk '\$11 >= 50000' > ../{output.path_mashmap})
EOF

chmod +x ./prepare_ref_mashmap.sh

./prepare_ref_mashmap.sh > ../{log.err} 2>&1
        '''
  


rule run_seqtktelo:
    input:
        unitigs = '8-hicPipeline/unitigs.fasta'
    output:
        unitigs_telo = '8-hicPipeline/unitigs.telo'
    log:
        err    = '8-hicPipeline/run_seqtktelo.err'
    params:
        SEQTK   = config.get('SEQTK', "{VERKKO}/bin/seqtk"),
        TELO    = config.get("telomere_motif", "CCCTAA"),
    threads:
        int(config['fhc_n_cpus'])

    resources:
        job_id = 1,
        n_cpus = int(config['fhc_n_cpus']),
        mem_gb = lambda wildcards, input, attempt: getMemoryRequest(attempt, 'fhc'),
        time_h = lambda wildcards, input, attempt: getTimeRequest(attempt, 'fhc')
    shell:
        '''
cd 8-hicPipeline

cat > ./run_seqtktelo.sh <<EOF
#!/bin/sh
set -e
echo "---Running seqtk telo"
{params.SEQTK} telo -m {params.TELO} ../{input.unitigs} > ../{output.unitigs_telo}
EOF

chmod +x ./run_seqtktelo.sh

./run_seqtktelo.sh > ../{log.err} 2>&1
        '''




#a lot of code duplication with 3-alignONT stages
def splitHICoutputs(wildcards):
#here we need only wildcards, right?
    return glob_wildcards("8-hicPipeline/split/hic1{xxxx}.fasta.gz").xxxx

# there is no use of base quality in bwa, so it's OK to use fasta_partition.py

checkpoint splitHIC:
    input:
        hic1           = HIC_READS1,
        hic2           = HIC_READS2	if config['withPOREC'] == "False" else rules.emptyfile.output[0]
    output:
        split_finished = '8-hicPipeline/splitHIC.finished'
    log:
        err            = '8-hicPipeline/splitHIC.err'
    params:
        bases          = config['shc_bases'] if config['withPOREC'] == "False" else config['spl_bases'],
        reads          = config['shc_reads'],
        length         = config['shc_min_length'],
    threads:
        int(config['fhc_n_cpus'])
    resources:
        job_id = 1,
        n_cpus = int(config['fhc_n_cpus']),
        mem_gb = lambda wildcards, input, attempt: getMemoryRequest(attempt, 'fhc'),
        time_h = lambda wildcards, input, attempt: getTimeRequest(attempt, 'fhc')
    shell:
        '''
cd 8-hicPipeline

cat > ./splitHIC.sh <<EOF
#!/bin/sh
set -e

mkdir -p split
if [ "{input.hic2}" = "emptyfile" ]; then
   {PYTHON} {VERKKO}/scripts/fasta_partition.py \\\\
     partition split/hic1 {params.bases} {params.reads} {params.length} False False \\\\
     {input.hic1} \\\\
    && \\\\
    touch ../{output.split_finished}
else
   {PYTHON} {VERKKO}/scripts/fasta_partition.py \\\\
     partition split/hic1 {params.bases} {params.reads} {params.length} False False \\\\
     {input.hic1} \\\\
    && \\\\
    {PYTHON} {VERKKO}/scripts/fasta_partition.py \\\\
      partition split/hic2 {params.bases} {params.reads} {params.length} False False \\\\
      {input.hic2} \\\\
    && \\\\
    touch ../{output.split_finished}
fi
EOF

chmod +x ./splitHIC.sh

./splitHIC.sh > ../{log.err} 2>&1
        '''

rule indexBWA:
    input:
        unitigs = '8-hicPipeline/unitigs.fasta'
    output:
        index   = '8-hicPipeline/unitigs.fasta.bwt'
    log:
        err     = '8-hicPipeline/index_bwa.err'
    params:
        BWA     = config.get('BWA', "{VERKKO}/bin/bwa")
    resources:
        job_id  = 1,
        n_cpus  = int(config['fhc_n_cpus']),
        mem_gb  = lambda wildcards, input, attempt: getMemoryRequest(attempt, 'fhc'),
        time_h  = lambda wildcards, input, attempt: getTimeRequest(attempt, 'fhc')
    shell:
        '''
cd 8-hicPipeline

cat > ./index_bwa.sh <<EOF
#!/bin/sh
set -e
echo "---Creating BWA index for {input.unitigs}"
{params.BWA} index ../{input.unitigs}
EOF

chmod +x ./index_bwa.sh
./index_bwa.sh > ../{log.err} 2>&1

        '''

rule alignBWA:
    input:
        unitigs = '8-hicPipeline/unitigs.fasta',
        hic1    = '8-hicPipeline/split/hic1{nnnn}.fasta.gz',
        hic2    = '8-hicPipeline/split/hic2{nnnn}.fasta.gz' if config['withPOREC'] == "False" else rules.emptyfile.output[0],
        index   = '8-hicPipeline/unitigs.fasta.bwt'         if config['withPOREC'] == "False" else rules.emptyfile.output[0]
    output:
        bwa_mapping = '8-hicPipeline/mapped{nnnn}.bam'
    log:
        err    = '8-hicPipeline/align_bwa{nnnn}.err'
    params:
        BWA       = config.get('BWA', "{VERKKO}/bin/bwa"),
        SAMTOOLS  = config.get('SAMTOOLS', "{VERKKO}/bin/samtools"),
        MINIMAP   = config.get('MINIMAP', "{VERKKO}/bin/minimap2"),
        withporec = config['withPOREC']
    threads:
        int(config['ahc_n_cpus'])
    resources:
        job_id = lambda wildcards, input, attempt: int(wildcards.nnnn),
        n_cpus = int(config['ahc_n_cpus']),
        mem_gb = lambda wildcards, input, attempt: getMemoryRequest(attempt, 'ahc'),
        time_h = lambda wildcards, input, attempt: getTimeRequest(attempt, 'ahc', 5.0)
    shell:
        '''
cd 8-hicPipeline

cat > ./align_bwa{wildcards.nnnn}.sh <<EOF
#!/usr/bin/env bash
set -e -o pipefail

if [ {params.withporec} = "False" ] ; then
   echo "---Mapping {input.hic1} and {input.hic2} to {input.unitigs} with BWA"
   {params.BWA} mem -t {threads} -5 -S -P ../{input.unitigs} ../{input.hic1} ../{input.hic2} | {params.SAMTOOLS} view -bh -@ {threads}  -F 0x900 - | {params.SAMTOOLS} sort -n -@ 24 - |  {PYTHON} {VERKKO}/scripts/hic_prefilter.py > ../{output.bwa_mapping}
else
   echo "--Mapping {input.hic1} to {input.unitigs} with minimap2"
   mem=\`expr {resources.mem_gb} \/ {threads} | awk '{{print \$1"G"}}' \`
   {params.MINIMAP} -ax map-ont -t {threads} -I40G -K \$mem ../{input.unitigs} ../{input.hic1} | {params.SAMTOOLS} view -T ../{input.unitigs} -bh -@ {threads} -q 3 -F 0x100 - | {params.SAMTOOLS} sort -n -@ {threads} - -o ../{output.bwa_mapping}
fi
EOF

chmod +x ./align_bwa{wildcards.nnnn}.sh

./align_bwa{wildcards.nnnn}.sh > ../{log.err} 2>&1
        '''

#TODO: remember porec 
rule scaffoldPrefilterBAM:
    input:
        bwa_mapping = '8-hicPipeline/mapped{nnnn}.bam',
        ids_list = '8-hicPipeline/scaffolding_nodes.list'
    output:
        bwa_filtered_mapping = '8-hicPipeline/mapped{nnnn}_nodefiltered.bam'
    log:
        err    = '8-hicPipeline/scaffold_prefilter{nnnn}.err'
    params:
        SAMTOOLS  = config.get('SAMTOOLS', "{VERKKO}/bin/samtools"),
        withporec = config['withPOREC']
    threads:
        int(config['ahc_n_cpus'])
    resources:
        job_id = lambda wildcards, input, attempt: int(wildcards.nnnn),
        n_cpus = int(config['ahc_n_cpus']),
        mem_gb = lambda wildcards, input, attempt: getMemoryRequest(attempt, 'ahc'),
        time_h = lambda wildcards, input, attempt: getTimeRequest(attempt, 'ahc', 5.0)
    shell:
        '''
cd 8-hicPipeline

cat > ./scaffold_prefilter{wildcards.nnnn}.sh <<EOF
#!/usr/bin/env bash
set -e -o pipefail

{PYTHON} {VERKKO}/scripts/scaffolding/scaff_prefilter.py ../{input.bwa_mapping} ../{output.bwa_filtered_mapping} ../{input.ids_list}

EOF

chmod +x ./scaffold_prefilter{wildcards.nnnn}.sh

./scaffold_prefilter{wildcards.nnnn}.sh > ../{log.err} 2>&1
        '''

rule scaffoldMergeBWA:
    input:
        split_finished = rules.splitHIC.output.split_finished,
        alignments     = lambda wildcards: expand("8-hicPipeline/mapped{nnnn}_nodefiltered.bam", nnnn = splitHICoutputs(wildcards))
    output:
        alignments     = '8-hicPipeline/hic_nodefiltered.bam'
    log:
        err            = '8-hicPipeline/scaffold_mergeBWA.err'
    params:
        SAMTOOLS       = config.get('SAMTOOLS', "{VERKKO}/bin/samtools"),
        alignments     = lambda wildcards: expand("mapped{nnnn}_nodefiltered.bam", nnnn = splitHICoutputs(wildcards)),
        alignments_old = lambda wildcards: expand("mapped{nnnn}.bam", nnnn = splitHICoutputs(wildcards)),
        keepinter      = config['keep_intermediate']
    threads:
        int(config['fhc_n_cpus'])
    resources:
        job_id = 1,
        n_cpus = int(config['fhc_n_cpus']),
        mem_gb = lambda wildcards, input, attempt: getMemoryRequest(attempt, 'fhc'),
        time_h = lambda wildcards, input, attempt: getTimeRequest(attempt, 'fhc')
    shell:
        '''
cd 8-hicPipeline

cat > ./scaffold_mergeBWA.sh <<EOF
#!/bin/sh
set -e

{params.SAMTOOLS} merge -n -@ {threads}  ../{output.alignments} {params.alignments}

if [ {params.keepinter} = False ] ; then
  rm -f {params.alignments}
  rm -f {params.alignments_old}

  rm -f ./align_bwa*.err
  rm -f ./align_bwa*.sh
  rm -f ./scaffold_prefilter*.err
  rm -f ./scaffold_prefilter*.sh

  rm -f ./unitigs.fasta.*
fi

EOF

chmod +x ./scaffold_mergeBWA.sh

./scaffold_mergeBWA.sh > ../{log.err} 2>&1
        '''


rule mergeBWA:
    input:
        split_finished = rules.splitHIC.output.split_finished,
        alignments     = lambda wildcards: expand("8-hicPipeline/mapped{nnnn}.bam", nnnn = splitHICoutputs(wildcards))

    output:
        alignments     = '8-hicPipeline/unique_mappings.bam'
    log:
        err            = '8-hicPipeline/mergeBWA.err'
    params:
        SAMTOOLS       = config.get('SAMTOOLS', "{VERKKO}/bin/samtools"),
        alignments     = lambda wildcards: expand("mapped{nnnn}.bam", nnnn = splitHICoutputs(wildcards)),
    threads:
        int(config['fhc_n_cpus'])
    resources:
        job_id = 1,
        n_cpus = int(config['fhc_n_cpus']),
        mem_gb = lambda wildcards, input, attempt: getMemoryRequest(attempt, 'fhc'),
        time_h = lambda wildcards, input, attempt: getTimeRequest(attempt, 'fhc')
    shell:
        '''
cd 8-hicPipeline

cat > ./mergeBWA.sh <<EOF
#!/bin/sh
set -e

{params.SAMTOOLS} merge -n -@ {threads}  - {params.alignments} | samtools view -q 1 -o ../{output.alignments}


EOF

chmod +x ./mergeBWA.sh

./mergeBWA.sh > ../{log.err} 2>&1
        '''

rule transformBWA:
    input:
        bwa_mapping = rules.mergeBWA.output.alignments,
    output:
        byread_mapping = '8-hicPipeline/hic_mapping.byread.output'
    log:
        err    = '8-hicPipeline/transform_bwa.err'
    params:
        SAMTOOLS = config.get('SAMTOOLS', "{VERKKO}/bin/samtools")
    threads:
        int(config['fhc_n_cpus'])
    resources:
        job_id = 1,
        n_cpus = int(config['fhc_n_cpus']),
        mem_gb = lambda wildcards, input, attempt: getMemoryRequest(attempt, 'fhc'),
        time_h = lambda wildcards, input, attempt: getTimeRequest(attempt, 'fhc')
    shell:
        '''
cd 8-hicPipeline

cat > ./transform_bwa.sh <<EOF
#!/bin/sh
set -e

{params.SAMTOOLS} view -q 1 ../{input.bwa_mapping} | {PYTHON} {VERKKO}/scripts/parse_sam_pairs.py  > ../{output.byread_mapping}
EOF

chmod +x ./transform_bwa.sh

./transform_bwa.sh > ../{log.err} 2>&1
        '''

rule hicPhasing:
    input:
        mashmap_matches = rules.runMashMap.output.unitigs_hpc50,
        mashmap_nohpcmatches = rules.runMashMap.output.unitigs_nonhpc50,
        hicmapping_byread = '8-hicPipeline/hic_mapping.byread.output',
        graph='8-hicPipeline/unitigs.hpc.noseq.gfa'
    output:
        hic_compressed = '8-hicPipeline/hic.byread.compressed',
        hic_binned_unitigs = '8-hicPipeline/hicverkko.colors.tsv'
    log:
        err    = '8-hicPipeline/hic_phasing.err'
    threads:
        int(config['fhc_n_cpus'])
    params:
        NO_RDNA = config['no_rdna_tangle'],
        UNEVEN_DEPTH = config['uneven_depth']
    resources:
        job_id = 1,
        n_cpus = int(config['fhc_n_cpus']),
        mem_gb = lambda wildcards, input, attempt: getMemoryRequest(attempt, 'fhc'),
        time_h = lambda wildcards, input, attempt: getTimeRequest(attempt, 'fhc')
    shell:
        '''
cd 8-hicPipeline

cat > ./hic_phasing.sh <<EOF
#!/bin/sh
set -e
{PYTHON} {VERKKO}/scripts/launch_phasing.py {params.NO_RDNA} {params.UNEVEN_DEPTH} .
EOF

chmod +x ./hic_phasing.sh

./hic_phasing.sh > ../{log.err} 2>&1
        '''

rule runRukkiHIC:
    input:
        graph = '8-hicPipeline/unitigs.hpc.noseq.gfa',
        binning = '8-hicPipeline/hicverkko.colors.tsv'
    output:
        tsv_path = '8-hicPipeline/rukki.paths.tsv',
        gaf_path = '8-hicPipeline/rukki.paths.gaf',
        prescaf_tsv_path = '8-hicPipeline/prescaf_rukki.paths.tsv',
        prescaf_gaf_path = '8-hicPipeline/prescaf_rukki.paths.gaf',

        final_paths_tsv = 'assembly.paths.tsv'
    log:
        err    = '8-hicPipeline/rukki_hic.err'
    threads:
        int(config['fhc_n_cpus'])
    resources:
        job_id = 1,
        n_cpus = int(config['fhc_n_cpus']),
        mem_gb = lambda wildcards, input, attempt: getMemoryRequest(attempt, 'fhc'),
        time_h = lambda wildcards, input, attempt: getTimeRequest(attempt, 'fhc')
    shell:
        '''
cd 8-hicPipeline

cat > ./rukki_hic.sh <<EOF
#!/bin/sh
set -e
echo "---Running rukki on the resulting clustering"
params=" --init-assign out_init_ann.csv --refined-assign out_refined_ann.csv --final-assign out_final_ann.csv"
params="\$params --marker-sparsity 5000"
params="\$params --issue-sparsity 1000"
params="\$params --try-fill-bubbles"
params="\$params --fillable-bubble-diff 1000"
params="\$params --fillable-bubble-len 500000"
params="\$params --assign-tangles --tangle-allow-deadend"
params="\$params --issue-ratio 1."
params="\$params --solid-homozygous-cov-coeff 1.1"
params="\$params --solid-ratio 1.5"
params="\$params --hap-names haplotype1,haplotype2"
params="\$params --max-homozygous-len=25000000"
params="\$params --trusted-len 325000"

{VERKKO}/bin/rukki trio -g ../{input.graph} -m ../{input.binning}              -p ../{output.prescaf_tsv_path} \$params
{VERKKO}/bin/rukki trio -g ../{input.graph} -m ../{input.binning} --gaf-format -p ../{output.prescaf_gaf_path} \$params
cp ../{output.prescaf_tsv_path} ../{output.tsv_path}
cp ../{output.prescaf_tsv_path} ../{output.final_paths_tsv}
cp ../{output.prescaf_gaf_path} ../{output.gaf_path}

echo "haplotype1" > label1
echo "haplotype2" > label2

EOF

chmod +x ./rukki_hic.sh

./rukki_hic.sh > ../{log.err} 2>&1
        '''

#TODO: python script params

rule HiC_rdnascaff:
    input:
        graph = '8-hicPipeline/unitigs.hpc.noseq.gfa',
        tsv_path = '8-hicPipeline/prescaf_rukki.paths.tsv',
        gaf_path = '8-hicPipeline/prescaf_rukki.paths.gaf',
        unitigs_telo = '8-hicPipeline/unitigs.telo',
        unitigs_nohpc50 =  '8-hicPipeline/unitigs_nonhpc50.mashmap',
        path_mashmap = rules.prepareScaffolding.output.path_mashmap,
        contigs = rules.copyFiles.output.unitig_fasta,
        prefiltered_aln = rules.scaffoldMergeBWA.output.alignments if config['withPOREC'] == "False" else rules.transformBWA.output.byread_mapping
    output:
        scaff_tsv_path = '8-hicPipeline/scaff_rukki.paths.tsv',
        scaff_gaf_path = '8-hicPipeline/scaff_rukki.paths.gaf',
        final_tsv_path = '8-hicPipeline/rukki.paths.tsv',
        final_gaf_path = '8-hicPipeline/rukki.paths.gaf',
    params:
        withporec = config['withPOREC']
    log:
        err    = '8-hicPipeline/hic_scaff.err'
    threads:
        int(config['shc_n_cpus'])
    resources:
        job_id = 1,
        n_cpus = int(config['shc_n_cpus']),
        mem_gb = lambda wildcards, input, attempt: getMemoryRequest(attempt, 'shc'),
        time_h = lambda wildcards, input, attempt: getTimeRequest(attempt, 'shc')
    shell:
        '''
cd 8-hicPipeline

cat > ./hic_scaff.sh <<EOF
#!/bin/sh
set -e
{PYTHON} {VERKKO}/scripts/launch_scaffolding.py . {params.withporec}


cp ../{output.scaff_tsv_path} ../{output.final_tsv_path}
cp ../{output.scaff_gaf_path} ../{output.final_gaf_path}

cp ../{output.final_tsv_path} ../{rules.runRukkiHIC.output.final_paths_tsv}
EOF

chmod +x ./hic_scaff.sh

./hic_scaff.sh > ../{log.err} 2>&1
        '''
